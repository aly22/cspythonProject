{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "optional-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "from PIL import Image,ImageDraw,ImageFont\n",
    "import pytesseract\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import display\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "# loading the face detection classifier\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_face.xml')\n",
    "#1 lets iterate through the images in the zip file\n",
    "#2 lets try to pytessaract it and load each pictures text in a dictionary of lists where lists are the values and images are the keys\n",
    "#3 lets opencv the images on by one if there are faces inside of themand crop out the pictures of faces\n",
    "#4 lets create aconact sheet 500 width and height scalablebased on the count of the items returnd by the opencv function \n",
    "## (if len opencv/5\n",
    "#5 lets fill in the contact sheet with faces foud by our pencv function \n",
    "#6 if the picture contains text aka if something is returned by the tesseract function and the opencv function returns\n",
    "## face images for the text containedimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "biological-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for the zipfile eextraction\n",
    "def zipfile_extrct(zipf):\n",
    "    #aaccumulator list for the images in zip file\n",
    "    images=[]\n",
    "    filenames=[]\n",
    "    # https://docs.python.org/3/library/zipfile.html\n",
    "    with zipfile.ZipFile(zipf) as myzip:\n",
    "        for img in myzip.infolist():\n",
    "            #https://stackoverflow.com/questions/21357184/using-python-opencv-to-load-image-from-zip\n",
    "            data=myzip.read(img)\n",
    "            image=cv.imdecode(np.frombuffer(data,np.uint8),1)\n",
    "            images.append(image)\n",
    "            filenames.append(img.filename)\n",
    "    return images,filenames\n",
    "images,filenames=zipfile_extrct(\"images.zip\")\n",
    "pil_images_bw=[]\n",
    "pil_images=[]\n",
    "opencv_ver_imgs=[]\n",
    "for image in images:\n",
    "    pil_img_bw=Image.fromarray(cv.cvtColor(image,cv.COLOR_BGR2GRAY),\"L\")\n",
    "    pil_img=Image.fromarray(cv.cvtColor(image,cv.COLOR_BGR2RGB),\"RGB\")\n",
    "    opencv_ver_img=cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "    pil_images_bw.append(pil_img_bw)\n",
    "    pil_images.append(pil_img)\n",
    "    opencv_ver_imgs.append(opencv_ver_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "recorded-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_from_images(pil_images_bw):\n",
    "    #extractng the ocred version from the images\n",
    "    strings_from_images=[]\n",
    "    for image in pil_images_bw:\n",
    "        str1=pytesseract.image_to_string(image)\n",
    "        strings_from_images.append(str1)\n",
    "    return strings_from_images\n",
    "# help(pytesseract.image_to_string)\n",
    "strings_from_images=str_from_images(pil_images_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "sufficient-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_rec(opencv_imgs):\n",
    "    faces=[]\n",
    "    i=0\n",
    "    for cv_img in opencv_imgs:\n",
    "        faces.append((face_cascade.detectMultiScale(cv_img,1.5)))\n",
    "    return faces\n",
    "faces=facial_rec(opencv_ver_imgs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "acoustic-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(faces:list,pil_images:list)->list:\n",
    "    faces_colored=[]\n",
    "    for i,face in enumerate(faces):\n",
    "        faces_list=[]\n",
    "        for x,y,w,h in face:\n",
    "            newimage=pil_images[i].crop((x,y,x+w,y+h))\n",
    "            faces_list.append(newimage)\n",
    "        faces_colored.append(faces_list)\n",
    "    return faces_colored\n",
    "faces_colored=get_faces(faces,pil_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "realistic-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<PIL.Image.Image image mode=RGB size=500x25 at 0x22B05C8E280>, <PIL.Image.Image image mode=RGB size=500x200 at 0x22B05CAA4C0>], [<PIL.Image.Image image mode=RGB size=500x25 at 0x22B05C8ECD0>, <PIL.Image.Image image mode=RGB size=500x200 at 0x22B05B4ECD0>], [<PIL.Image.Image image mode=RGB size=500x25 at 0x22B05B9D6D0>, <PIL.Image.Image image mode=RGB size=500x25 at 0x22B05C8E6D0>], [<PIL.Image.Image image mode=RGB size=500x25 at 0x22B05B9D820>, <PIL.Image.Image image mode=RGB size=500x100 at 0x22B05C8EB20>], [<PIL.Image.Image image mode=RGB size=500x25 at 0x22B05C8ED00>, <PIL.Image.Image image mode=RGB size=500x100 at 0x22B05BCC4F0>], [<PIL.Image.Image image mode=RGB size=500x25 at 0x22B05BCC460>, <PIL.Image.Image image mode=RGB size=500x100 at 0x22B019ED040>], [<PIL.Image.Image image mode=RGB size=500x25 at 0x22B03BE1C10>, <PIL.Image.Image image mode=RGB size=500x100 at 0x22B05BC1340>]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"I TRIED TO REMOVE THE TEXT FROM THE PICTURES, HELL I EVEN TRIED TO DO THE FACIAL RECOGNITION TWICE\n",
    "Then i searched for this on the forums then found out that 1.5 scalefactor should do it XD (2 days of trying)\"\"\"\n",
    "def hope_the_rest(faces_colored,filenames,strings_from_images,word=\"Mark\"):\n",
    "    font=ImageFont.truetype(r\"C:\\Users\\ALI-Gsus\\anaconda3\\envs\\py3env\\lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans.ttf\",16)\n",
    "    d={}\n",
    "    width=500\n",
    "    height=100\n",
    "    height_of_text=25\n",
    "    for i, file in enumerate(filenames):\n",
    "            d[file]=faces_colored[i]\n",
    "            \n",
    "    contact_sheets=[]\n",
    "    for i,(k,v) in enumerate(d.items()):\n",
    "        \n",
    "        if word in strings_from_images[i]:\n",
    "            contact_sheet2=Image.new(\"RGB\",color=(255,255,55),size=(width,height_of_text))\n",
    "            drawing=ImageDraw.Draw(contact_sheet2)\n",
    "            drawing.text((0,height_of_text/3),f\"Results found in file {filenames[i]}\",fill=(0,0,0),font=font)\n",
    "\n",
    "            if math.ceil(len(v)/5)==2:\n",
    "                height+=100\n",
    "                \n",
    "            if len(v)>0:\n",
    "                x=0\n",
    "                y=0\n",
    "                contact_sheet=Image.new(\"RGB\",(width,height))\n",
    "                height=100\n",
    "                for img in v:\n",
    "                    img.thumbnail((100,100))\n",
    "                    contact_sheet.paste(img, (x, y) )\n",
    "\n",
    "                    if x+100 == contact_sheet.width:\n",
    "                        x=0\n",
    "                        y=y+100\n",
    "                    else:\n",
    "                        x=x+100\n",
    "            else:\n",
    "                contact_sheet=Image.new(\"RGB\",(width,height_of_text),color=(255,255,55))\n",
    "                drawing=ImageDraw.Draw(contact_sheet)\n",
    "                drawing.text((0,height_of_text/3),\"But there were no faces in that file!\",fill=(0,0,0),font=font)\n",
    "\n",
    "\n",
    "\n",
    "            contact_sheets.append([contact_sheet2,contact_sheet])\n",
    "\n",
    "    return contact_sheets\n",
    "        \n",
    "\n",
    "\n",
    "print(hope_the_rest(faces_colored,filenames,strings_from_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "naked-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thats_it(faces_colored,filenames,strings_from_images,word=\"Christoher\"):\n",
    "    contact_sheets=hope_the_rest(faces_colored,filenames,strings_from_images,word)\n",
    "    cs_height=0\n",
    "    css_height=0\n",
    "    cs_width=500\n",
    "    for ontact_sheet in contact_sheets:\n",
    "        for cs in contact_sheet:\n",
    "            cs_height+=cs.height\n",
    "    css=Image.new(\"RGB\",(cs_width,cs_height))\n",
    "    for contact_sheet in contact_sheets:\n",
    "        for cs in contact_sheet:\n",
    "            css.paste(cs)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "constitutional-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "thats_it(faces_colored,filenames,strings_from_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
